{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef3f5591",
   "metadata": {},
   "source": [
    "# Building Deep Learning Applications with Keras 2.0\n",
    "**Instructor:** Adam Geitgey\n",
    "\n",
    "Keras is a popular programming framework for deep learning that simplifies the process of building deep learning applications. Instead of providing all the functionality itself, it uses either TensorFlow or Theano behind the scenes and adds a standard, simplified programming interface on top. In this course, learn how to install Keras and use it to build a simple deep learning model. Explore the many powerful pre-trained deep learning models included in Keras and how to use them. Discover how to deploy Keras models, and how to transfer data between Keras and TensorFlow so that you can take advantage of all the TensorFlow tools while using Keras. When you wrap up this course, you'll be ready to start building and deploying your own models with Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe679486",
   "metadata": {},
   "source": [
    "* **Keras:** A high-level framework for building neural networks with only a few lines of code\n",
    "    * Backends: Keras doesn't do all of the work itself; it uses either **TensorFlow** or **Theano** behind the scenes to do all of its calculations. Keras abstracts away a lot of the complexity of using those tools while still giving you many of the benefits.\n",
    "    * Best practices are built-in to Keras\n",
    "    * The default settings in Keras as designed to give you good results in most cases\n",
    "    * Keras comes with several pre-trained built-in models for image recognition; you can use the pre-trained models to recognize common objects in images or **you can adapt these models to create a custom image recognition system with your own data**\n",
    "    \n",
    "#### Keras backends\n",
    "* Keras is a **front-end layer** that relies on a separate, deep learning, **back-end library** under the hood for the processing\n",
    "* Keras supports multiple backends, including:\n",
    "    * TensorFlow (by Google)\n",
    "    * Theano (by University of Montreal)\n",
    "\n",
    "#### Theano\n",
    "* Created at MILA (Montreal Institute for Learning Algorithms) at the University of Montreal\n",
    "* Theano has been around for a decade (much longer than TensorFlow)\n",
    "* It has been the tool behind many breakthroughs in ML research\n",
    "* Works well with Python\n",
    "* Fullt supports GPU acceleration\n",
    "\n",
    "#### TensorFlow\n",
    "* Created at Google in 2015\n",
    "* Google uses TensorFlow internally to build many of their popular services, like GoogleTranslate\n",
    "* Advanced support for distributed processing across multiple\n",
    "* TensorFlow works with Google's cloud ML platform\n",
    "* It's even easy to switch between Theano and TensorFlow with Keras\n",
    "\n",
    "\n",
    "* The decsion to use either Theano or TensorFlow often depends on the other tools you wish to use with your project and which library supports them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9dc3d6d",
   "metadata": {},
   "source": [
    "#### Using Keras vs. TensorFlow\n",
    "\n",
    "<img src='../data/keras1.png' width=\"600\" height=\"300\" align=\"center\"/>\n",
    "\n",
    "* In this course we'll be using Keras with a TensorFlow backend\n",
    "* TensorFlow gives you more control over almost every detail, whereas Keras offers fast and easy experimentation\n",
    "* When is using TensorFlow alone a better choice?\n",
    "    * Researching new types of machine learning models\n",
    "    * Building a large-scale system to support many users\n",
    "    * If processing and memory efficiency is more important than time saved while coding\n",
    "* When to choose Keras?\n",
    "    * Education and experimentation\n",
    "    * Prototyping\n",
    "    * Producton systems that don't have highly specialized requirements\n",
    "    \n",
    "#### Supervised Learning\n",
    "* The branch of machine learning where the computer learns how to perform a function by looking at labeled training data\n",
    "\n",
    "#### Customizable layer settings\n",
    "* Layer activation function\n",
    "* Initializer function for node weights\n",
    "* Regulariztion funciton for node weights\n",
    "* But remember that default settings are a good start\n",
    "\n",
    "#### Types of layers\n",
    "* Dense\n",
    "    * Example: `keras.layers.Dense()`\n",
    "* Convolutional\n",
    "    * Example: `keras.layers.convolutional.Conv2D()`\n",
    "    * Usually used to process images or spatial data\n",
    "* Recurrent\n",
    "    * Example: `keras.layers.recurrent.LSTM()`\n",
    "    * Special layers that have a \"memory\" built-in to each neuron\n",
    "    * Useful for processing sequential data (like sentences, where many previous words are used to help determine the meaning and context of a given word).\n",
    "* You can mix layers of different types in a single model\n",
    "\n",
    "### Neural networks train best when data in each column is each scaled to the same range (often 0-1)\n",
    "\n",
    "```\n",
    "# Data needs to be scaled to a small range like 0 to 1 for the neural network to work well.\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# Scale both the training inputs and outputs\n",
    "scaled_training = scaler.fit_transform(training_data_df)\n",
    "scaled_testing = scaler.transform(test_data_df)\n",
    "\n",
    "# Print out the adjustment that the scaler applied to the total_earnings column of data\n",
    "print(\"total_earnings values were scaled by multiplying by {:.10f} and adding {:.6f}\".format(scaler.scale_[8], \n",
    "                                                            scaler.min_[8]))\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a11bcb",
   "metadata": {},
   "source": [
    "* **Note:** default `activation` is `linear`\n",
    "* When we compile the model, we have to specify the loss function. The loss function is how Keras measures how close the NN's predictions are to the expected values. `mse` or `mean_squared_error` is the most common loss function\n",
    "* A good choice for optimizer that works for most ML tasks is `adam`\n",
    "\n",
    "#### Training and evaluating the model\n",
    "* `model.fit()`\n",
    "* The most important parameters we have to pass in are the training features and the expected output\n",
    "* **epoch:** A single training pass across the entire training dataset is called an epoch\n",
    "    * If we do too few passes, the NN won't make accurate predictions\n",
    "    * If we do too many, it will waste time and might also cause overfitting problems\n",
    "    * The best way to tune this is to try training the neural network and stop doing additional training passes when the network stops getting more accurate\n",
    "* We can also ask Keras to shuffle the order of the training data randomly\n",
    "    * Note that NN's typically train best when the data is shuffled\n",
    "* `verbose=2` tells Keras to print more detailed information during training so we can watch what's going on.\n",
    "\n",
    "```\n",
    "# Load the separate test data set\n",
    "test_data_df = pd.read_csv(\"sales_data_test_scaled.csv\")\n",
    "\n",
    "X_test = test_data_df.drop('total_earnings', axis=1).values\n",
    "Y_test = test_data_df[['total_earnings']].values\n",
    "\n",
    "test_error_rate = model.evaluate(X_test, Y_test, verbose = 0)\n",
    "print(\"The mean squared error (MSE) for the test data set is: {}\".format(test_error_rate))\n",
    "```\n",
    "\n",
    "* The above code may generate some warnings from TensorFlow, but that's normal and don't worry about it (according to Adam Geitgey)\n",
    "* The smaller the error term, the better (it means that the neural network is making predictions that are, on average, very close to the actual values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548a752e",
   "metadata": {},
   "source": [
    "#### Making predictions\n",
    "* **One trick to watch out for:** Keras always assumes that we are going to ask for multiple predictions with multiple output values in each prediction, so it **always returns predictions as a 2D array**\n",
    "* **Also remember:** Usually data is scaled before being processed through a NN. When this is the case, **always perform the reverse scale operations on predictions to calculate actual predicitions in their *original units*.**\n",
    "    * $\\star$ This is where having printed the multiplicative and additive constants from the scaling process becomes useful!!\n",
    "   \n",
    "#### Saving and loading models\n",
    "* So far, we've always retrained the NN every time we've used it, but *there are problems with this approach!!*\n",
    "    * Large neural networks can take hours or days to train; instead of retraining each time we run our program, we can train it once and save the results to a file. Then, whenever we want to use the neural network, we can just load it back up and use it\n",
    "* To save a Keras model:\n",
    "\n",
    "```\n",
    "# Save the model to disk\n",
    "model.save(\"trained_model.h5\")\n",
    "print(\"Model saved to disk.\")\n",
    "```\n",
    "* Note that `hdf5` is the standard format in which to save nn models; `.h5` means the data will be stored in the `hdf5` format\n",
    "* **hdf5** is a binary file format, designed for storing Python array data; the convention is to use `.h5` as the filename extension\n",
    "* **When you save the model, it saves both the structure of the neural network, and the trained weights that determine how the neural network work.**\n",
    "\n",
    "#### Load a model saved to disk\n",
    "\n",
    "```\n",
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('trained_model.h5')\n",
    "```\n",
    "* Since the file contains the structure and training parameters, this single line recreates our entire trained NN\n",
    "* We don't have to redeclare the structure of our neural network again\n",
    "* $\\star$ **We can now use the model we loaded exactly like any other model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720e7f09",
   "metadata": {},
   "source": [
    "## Pre-trained models in Keras\n",
    "* Not only can you build your own ML NN models with Keras, but you can use models built by other developers\n",
    "* Keras provides several popular image recognition models built-in\n",
    "* Just by installing Keras, you have access to pre-trained image recognition models that you can use in your own projects\n",
    "* The image recognition models included with Keras are all trained to recognize images from the ImageNet dataset\n",
    "* The **ImageNet dataset** is a collection of millions of pictures of objects that have been labelled so that you can use them to train computers to recognize those objects\n",
    "* **ILSVRC:** ImageNet Large-Scale Visual Recognition Challenge\n",
    "* The pre-trained models included with Keras are trained on the more limited data used by this contest: data set of 1,000 types of common objects\n",
    "\n",
    "### Image Recognition Models included with Keras (4)\n",
    "\n",
    "#### VGG (Visual Geometry Group at the University of Oxford)\n",
    "   * Deep NN with either 16 or 19 layers\n",
    "   * State-of-the-art in 2014\n",
    "   * Still widely used, but takes a lot of memory to run\n",
    "\n",
    "#### ResNet50 (Microsoft Research)\n",
    "   * State-of-the-art from 2015\n",
    "   * 50 layer NN \n",
    "   * Manages to be more accurate but still use less memory than the VGG design\n",
    "\n",
    "#### Inception-v3 (Google)\n",
    "   * Design from 2015 that also performs very well\n",
    "\n",
    "#### Xception (Fran√ßois Chollet, author of Keras)\n",
    "   * Xception is an improved version of Inception-v3\n",
    "   * More accurate than Inception-v3, while using the same amount of memory\n",
    "   \n",
    "* $\\star$ **Even if you want to recognize an object that's not in the 1,000 object training set, it's much faster to start with a pre-trained model and fine-tune it to your needs, instead of training your own model from scratch.** $\\star$\n",
    "\n",
    "* Also: $\\star$ **These models illustrate the progression of the state-of-the-art in image recognition. It's very useful to be familiar with these common neural network designs since they are so often re-used or adapted to solve real-world problems.** $\\star$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682bc186",
   "metadata": {},
   "source": [
    "### ResNet50\n",
    "* All of the pre-trained models included with Keras are in the `applications` package\n",
    "* Needs input images to be 224 pixels x 224 pixels\n",
    "* Note that using low-resolution images (like 224 x 224) is common even in the latest image recognition models.\n",
    "* **Remember that NNs work best with small numbers so we need to normalize the data before we feed it to the model. ResNet has a built-in normalization function called `preprocess_input()` which will do that for us.**\n",
    "\n",
    "\n",
    "```\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "from keras.applications import resnet50\n",
    "\n",
    "# Load Keras' ResNet50 model that was pre-trained against the ImageNet database\n",
    "model = resnet50.ResNet50()\n",
    "\n",
    "# Load the image file, resizing it to 224x224 pixels (required by this model)\n",
    "img = image.load_img(\"bay.jpg\", target_size=(224, 224))\n",
    "\n",
    "# Convert the image to a numpy array\n",
    "x = image.img_to_array(img)\n",
    "\n",
    "# Add a forth dimension since Keras expects a list of images\n",
    "x = np.expand_dims(x, axis=0)\n",
    "\n",
    "# Scale the input image to the range used in the trained network\n",
    "x = resnet50.preprocess_input(x)\n",
    "\n",
    "# Run the image through the deep neural network to make a prediction\n",
    "predictions = model.predict(x)\n",
    "\n",
    "# Look up the names of the predicted classes. Index zero is the results for the first image.\n",
    "predicted_classes = resnet50.decode_predictions(predictions, top=9)\n",
    "\n",
    "print(\"This is an image of:\")\n",
    "\n",
    "for imagenet_id, name, likelihood in predicted_classes[0]:\n",
    "    print(\" - {}: {:2f} likelihood\".format(name, likelihood))\n",
    "```\n",
    "\n",
    "* **Note that `model.predict()` returns a predictions object.** The predictions object is a 1,000 element array of floating point numbers. Each element in the array tells us how likely a picture contains each of the 1,000 objects the model was trained to recognize.\n",
    "* `resnet50.decode_predictions()` decodes these prediction objects for us and by default gives us the top five most likely predictions\n",
    "    * However, if we add in `top=9` we'll get, for example, the top 9 most likely predictions\n",
    "    \n",
    "* **Note!!:** The first time you run the code, Keras will connect to the internet and download the latest version of the ResNet50 model. This means you'll need internet access to run it and about 100MB of data will be downloaded\n",
    "* **FOR MACS:** \n",
    "    * 1) Open Finder window\n",
    "    * 2) Go to Applications folder\n",
    "    * 3) Find Python 3 folder\n",
    "    * 4) Inside folder, run \"Install Certificates command\"\n",
    "* **Now you can run the model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fb6d38",
   "metadata": {},
   "source": [
    "## Monitoring a Keras model with TensorBoard\n",
    "\n",
    "### Export Keras logs in TensorFlow format\n",
    "* TensorFlow comes with a great web-based tool called **TensorBoard**, which lets us visualize our model's structure and monitor its training\n",
    "* To use TensorBoard, we need our Keras model to write log files in a format that TensorBoard can read\n",
    "* TensorBoard uses the information in these log files to generate its visualizations\n",
    "* Below we'll add TensorBoard logging to our Keras model\n",
    "\n",
    "```\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "\n",
    "training_data_df = pd.read_csv(\"sales_data_training_scaled.csv\")\n",
    "\n",
    "X = training_data_df.drop('total_earnings', axis=1).values\n",
    "Y = training_data_df[['total_earnings']].values\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Dense(50, input_dim=9, activation='relu', name='layer_1'))\n",
    "model.add(Dense(100, activation='relu', name='layer_2'))\n",
    "model.add(Dense(50, activation='relu', name='layer_3'))\n",
    "model.add(Dense(1, activation='linear', name='output_layer'))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "# Create a TensorBoard logger\n",
    "logger = keras.callbacks.TensorBoard(\n",
    "    log_dir='logs',\n",
    "    write_graph=True,\n",
    "    histogram_freq=5\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    X,\n",
    "    Y,\n",
    "    epochs=50,\n",
    "    shuffle=True,\n",
    "    verbose=2,\n",
    "    callbacks=[logger]\n",
    ")\n",
    "\n",
    "# Load the separate test data set\n",
    "test_data_df = pd.read_csv(\"sales_data_test_scaled.csv\")\n",
    "\n",
    "X_test = test_data_df.drop('total_earnings', axis=1).values\n",
    "Y_test = test_data_df[['total_earnings']].values\n",
    "\n",
    "test_error_rate = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"The mean squared error (MSE) for the test data set is: {}\".format(test_error_rate))\n",
    "```\n",
    "\n",
    "* Note that by default, Keras won't create any TensorFlow log files; to do that, we need to add a few lines of code\n",
    "\n",
    "#### TensorBoard syntax and parameters\n",
    "* `logger = keras.callbacks.TensorBoard(...)`\n",
    "* **Parameters:**\n",
    "    * `log_dir`: tell Keras which folder to write the log files to \n",
    "    * `write_graph`: True/False: tells Keras to log model structure\n",
    "    * `histogram_freq`: int: log extra statistics on how each layer of our NN is working; the `5` means that for every five passes through the training data, it will write out statistics; the more often you log data, obviously, the bigger the log files get\n",
    "    \n",
    "* Customize what data gets logged:\n",
    "    * By default Keras will only log details of the training process, but it won't log the structure of the model.\n",
    "    \n",
    "* **We also need to tell our model to use the logger when we call `model.fit()`**\n",
    "    * **`callbacks=[logger]`**\n",
    "    * Note that callbacks expects an array\n",
    "    \n",
    "#### Naming your layers\n",
    "* One more tweak to make the visualizations easier to read: name your layers and the name will show up in the TensorBoard visualization\n",
    "\n",
    "### Visualize the computational graph\n",
    "* It's always helpful to visualize what's happening with your data. This is where TensorBoard comes in; it let us visualize exactly what Kera's TensorFlow backend is doing\n",
    "* The `logdir` parameter tells TensorBoard which set of log files you want to visualize\n",
    "* **To open TensorBoard, open a terminal window**:\n",
    "    * `tensorboard --logdir=06/logs`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9064b67",
   "metadata": {},
   "source": [
    "<img src='../data/tensorboard1.png' width=\"800\" height=\"400\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e41bb1",
   "metadata": {},
   "source": [
    "<img src='../data/tensorboard2.png' width=\"900\" height=\"450\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df791123",
   "metadata": {},
   "source": [
    "<img src='../data/tensorboard3.png' width=\"900\" height=\"450\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49b13a9",
   "metadata": {},
   "source": [
    "<img src='../data/tensorboard4.png' width=\"600\" height=\"300\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b04dc1b",
   "metadata": {},
   "source": [
    "* Each line represents a tensor or array of data being passed between the layers. The numbers along the lines represent the size of the tensor or array\n",
    "* `? x 9`: `?` represents batch size\n",
    "* Click on a layer to expand:\n",
    "\n",
    "<img src='../data/tensorboard5.png' width=\"600\" height=\"300\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a317c8aa",
   "metadata": {},
   "source": [
    "* A \"neat\" feature in TensorBoard is the ability to trace the path of data through the graph\n",
    "* Let's see that we want to see what is required to generate an output from the neural network\n",
    "* Very helpful to debug what's going on, especially for complex models\n",
    "* There's a lot going on here (above) other than just the neural network itself\n",
    "    * When you use Keras, it will tend to build more complex TensorFlow models than what you would have built yourself if you were using TensorFlow directly\n",
    "    * Keras will try to build models that capture best practices that you may not even be aware of \n",
    "    * For example, **gradient clipping** can help prevent issues when you're training very deep neural networks and Keras always includes gradient clippng in your model by default"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3ed1f7",
   "metadata": {},
   "source": [
    "### Visualizing training progress\n",
    "* You'll often want to compare different neural network designs to see which gives you the best results with your training data\n",
    "* Using Tensorboard, we can visually monitor the progress of training as it happens and even compare different training runs against each other"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5d5462",
   "metadata": {},
   "source": [
    "### Exporting Google Cloud-compatible models\n",
    "* Now, you want to be able to scale your Keras model up in production to serve lots of users\n",
    "* Since we're using Keras with a TensorFlow backend, we can export our Keras model as a TensorFlow model\n",
    "* Once we have a TensorFlow model, we can upload that to the Google Cloud ML service\n",
    "* Using the Google Cloud ML service, we can use as many users as we need\n",
    "* To export this model as a TensorFlow model, we have to use some TensorFlow specific code\n",
    "* We create a TensorFlow `saved_model` builder object\n",
    "    * This object lets us save a TensorFlow model with custom options\n",
    "    * The only parameter is the name of the folder we want to save the model in \n",
    "* We also need to declare what the inputs and outputs of our model are\n",
    "* TensorFlow models can have several inputs and outputs so we need to tell TensorFlow which specific inputs and outputs we'll use when making predictions\n",
    "* Keras makes this easy; it keeps track of the input and output of our model for us so we just need to pass that to TensorFlow: `model.input` and `model.output`\n",
    "* We also have to create a TensorFlow **`signature_def`**:\n",
    "    * a `signature_def` is sort of like a function declaration in a programming language\n",
    "    * TF looks for this to know how to run the prediction function of our model\n",
    "    * **This code will be the same every time**\n",
    "* We also have to call TF's **`.add_meta_graph_and_variables()`** function:\n",
    "    * This tells TF that we want to save both the structure of our model and the current trained weights of the model \n",
    "    * First pass reference to current Keras session : `K.get_session()`\n",
    "    * Then assign model a special tag, `tags` so that TF knows this model is meant for serving users\n",
    "    * Lastly, pass in the `signature_def` created above\n",
    "        * This code will also be the same every time. \n",
    "    * **(Don't forget to save the model with `model_builder.save()`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046dfa5a",
   "metadata": {},
   "source": [
    "### Configuring a new Google Cloud account and project\n",
    "* A **Project** is a workspace within Google cloud\n",
    "* Each application you build can be set up as its own project\n",
    "* Your project will get assigned a unique project ID corresponding the the project title; this is the ID you'll use to access this project from your programs\n",
    "* Since the Google Cloud platform has so many features, not all of them are enabled by default\n",
    "    * For example, we need to enable the Google Cloud ML service before we can use it\n",
    "    \n",
    "#### Google Cloud SDK\n",
    "* The Google Cloud SDK is a set of tools that lets us work from the Google cloud service from our computer\n",
    "* `cloud.google.com/sdk/downloads`\n",
    "* The advantage of hosting your Keras model in the Google cloud is that it is accessible from anywhere in the world\n",
    "* Google servers will run the model and you are only charged based on how many requests are made\n",
    "* It's a great solution for using a Keras model in production if you don't want to maintain your own servers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a160bdaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
